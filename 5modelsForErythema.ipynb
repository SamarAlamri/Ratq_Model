{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMSVAoNraAr44+bwTb141Xs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamarAlamri/Ratq_Model/blob/main/5modelsForErythema.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U tensorflow==2.15.1 pandas numpy scikit-learn pillow tqdm matplotlib seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8u4oC8o2060",
        "outputId": "fa6299a6-80ae-4a16-9ed1-b59364b69c50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.15.1 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.15.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n"
      ],
      "metadata": {
        "id": "Ny0xj8_mq8Ka"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SamarAlamri/Ratq_Model.git\n",
        "%cd Ratq_Model\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8d4gSGBrCeU",
        "outputId": "602c4dc1-b745-4c62-905d-45b0b10ad0e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Ratq_Model'...\n",
            "remote: Enumerating objects: 6660, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 6660 (delta 1), reused 0 (delta 0), pack-reused 6657 (from 4)\u001b[K\n",
            "Receiving objects: 100% (6660/6660), 501.55 MiB | 16.44 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "Updating files: 100% (11352/11352), done.\n",
            "/content/Ratq_Model\n",
            "erythema_efficientnet_final.h5\t Ratq_Model_final.ipynb\n",
            "erythema_efficientnet_robust.h5  Ratq_Model_MobileNetV2.ipynb\n",
            "erythema_mobilenet_robust.h5\t requirements.txt\n",
            "erythema_model_final.h5\t\t SurgWound_Augmented\n",
            "erythema_model_finetuned.h5\t SurgWound_Augmented_Exudate_3Class\n",
            "exudate_model_final.h5\t\t SurgWound_Cleaned\n",
            "Ratq_Model_EfficientNetB0.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"SurgWound_Cleaned\"\n",
        "\n",
        "TRAIN_CSV = os.path.join(DATA_ROOT, \"train_data.csv\")\n",
        "VAL_CSV   = os.path.join(DATA_ROOT, \"validation_data.csv\")\n",
        "TEST_CSV  = os.path.join(DATA_ROOT, \"test_data.csv\")\n",
        "\n",
        "assert os.path.exists(TRAIN_CSV), \"Missing train_data.csv\"\n",
        "assert os.path.exists(VAL_CSV), \"Missing validation_data.csv\"\n",
        "assert os.path.exists(TEST_CSV), \"Missing test_data.csv\"\n",
        "\n",
        "print(\"âœ… DATA_ROOT:\", DATA_ROOT)\n",
        "print(\"âœ… CSVs found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDIVnPa7utV3",
        "outputId": "7b63f505-3395-4d9e-e93a-2bd4e9670cb4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… DATA_ROOT: SurgWound_Cleaned\n",
            "âœ… CSVs found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_erythema(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df = df[df[\"image_id\"].str.contains(\"erythema\", case=False, na=False)]\n",
        "    df = df[df[\"answer\"].str.lower() != \"uncertain\"]\n",
        "    df[\"answer\"] = df[\"answer\"].astype(str).str.strip()\n",
        "    return df.reset_index(drop=True)\n",
        "\n",
        "train_df = load_erythema(TRAIN_CSV)\n",
        "val_df   = load_erythema(VAL_CSV)\n",
        "test_df  = load_erythema(TEST_CSV)\n",
        "\n",
        "print(\"Train:\\n\", train_df[\"answer\"].value_counts())\n",
        "print(\"Val:\\n\", val_df[\"answer\"].value_counts())\n",
        "print(\"Test:\\n\", test_df[\"answer\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db-fGavEu3Pp",
        "outputId": "ca108476-4e77-4fa6-d141-17ade5df0424"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:\n",
            " answer\n",
            "Non-existent    334\n",
            "Existent        129\n",
            "Name: count, dtype: int64\n",
            "Val:\n",
            " answer\n",
            "Non-existent    44\n",
            "Existent        22\n",
            "Name: count, dtype: int64\n",
            "Test:\n",
            " answer\n",
            "Non-existent    91\n",
            "Existent        40\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_paths(df):\n",
        "    df = df.copy()\n",
        "    df[\"filename\"] = df[\"filename\"].astype(str)\n",
        "    df[\"filename\"] = df[\"filename\"].str.replace(\"\\\\\\\\\", \"/\", regex=False)\n",
        "    df[\"filename\"] = df[\"filename\"].str.replace(\"\\\\\", \"/\", regex=False)\n",
        "    return df\n",
        "\n",
        "train_df = fix_paths(train_df)\n",
        "val_df   = fix_paths(val_df)\n",
        "test_df  = fix_paths(test_df)\n",
        "\n",
        "# sanity check\n",
        "p = os.path.join(DATA_ROOT, train_df[\"filename\"].iloc[0])\n",
        "print(\"Example fixed filename:\", train_df[\"filename\"].iloc[0])\n",
        "print(\"Exists?\", os.path.exists(p))\n",
        "assert os.path.exists(p), \"âŒ Still cannot find images. Paths or folder structure mismatch.\"\n",
        "print(\"âœ… Paths fixed correctly\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3uzBTPNu5Bs",
        "outputId": "370b09e9-f467-4f8f-fd43-3649e02500fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example fixed filename: train/images/0.jpg_erythema.jpg\n",
            "Exists? True\n",
            "âœ… Paths fixed correctly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (300, 300)\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.08,\n",
        "    height_shift_range=0.08,\n",
        "    zoom_range=0.15,\n",
        "    brightness_range=[0.90, 1.10],\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_loader = train_gen.flow_from_dataframe(\n",
        "    train_df, DATA_ROOT,\n",
        "    x_col=\"filename\", y_col=\"answer\",\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"sparse\",\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = val_gen.flow_from_dataframe(\n",
        "    val_df, DATA_ROOT,\n",
        "    x_col=\"filename\", y_col=\"answer\",\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"sparse\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = val_gen.flow_from_dataframe(\n",
        "    test_df, DATA_ROOT,\n",
        "    x_col=\"filename\", y_col=\"answer\",\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"sparse\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"âœ… Train batches:\", len(train_loader))\n",
        "print(\"âœ… Class mapping:\", train_loader.class_indices)\n",
        "assert len(train_loader) > 0, \"âŒ Train loader is empty.\"\n",
        "assert train_loader.class_indices, \"âŒ No class indices.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV1L5t_Ou62f",
        "outputId": "b6b05789-c8b3-4143-8db5-345304db27fe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 463 validated image filenames belonging to 2 classes.\n",
            "Found 66 validated image filenames belonging to 2 classes.\n",
            "Found 131 validated image filenames belonging to 2 classes.\n",
            "âœ… Train batches: 29\n",
            "âœ… Class mapping: {'Existent': 0, 'Non-existent': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(train_loader.classes, dtype=int)\n",
        "classes = np.array(list(train_loader.class_indices.values()), dtype=int)\n",
        "\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=classes,\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "CLASS_WEIGHTS = {int(c): float(w) for c, w in zip(classes, weights)}\n",
        "\n",
        "print(\"Class indices:\", train_loader.class_indices)\n",
        "print(\"Class weights:\", CLASS_WEIGHTS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svt-cJawu88h",
        "outputId": "94a40a67-aaef-45e9-be4d-c4c45bb6aecc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class indices: {'Existent': 0, 'Non-existent': 1}\n",
            "Class weights: {0: 1.7945736434108528, 1: 0.6931137724550899}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_head(x, num_classes=2):\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    return layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "def compile_model(model, lr=1e-4):\n",
        "    model.compile(\n",
        "        optimizer=Adam(lr),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def fit_model(model, epochs=8, lr=1e-4):\n",
        "    compile_model(model, lr=lr)\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.5, min_lr=1e-6)\n",
        "    ]\n",
        "    model.fit(\n",
        "        train_loader,\n",
        "        validation_data=val_loader,\n",
        "        epochs=epochs,\n",
        "        class_weight=CLASS_WEIGHTS,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "def eval_argmax(model):\n",
        "    probs = model.predict(test_loader, verbose=0)\n",
        "    y_pred = np.argmax(probs, axis=1)\n",
        "    y_true = test_loader.classes\n",
        "    return (accuracy_score(y_true, y_pred),\n",
        "            f1_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n",
        "\n",
        "def best_threshold_on_val(model):\n",
        "    probs = model.predict(val_loader, verbose=0)\n",
        "    y_val = val_loader.classes\n",
        "\n",
        "    ex_idx = train_loader.class_indices[\"Existent\"]\n",
        "    p_ex = probs[:, ex_idx]\n",
        "\n",
        "    best_t, best_f1 = 0.5, -1\n",
        "    for t in np.arange(0.05, 0.96, 0.01):\n",
        "        y_pred_t = np.where(p_ex >= t, ex_idx, 1 - ex_idx)\n",
        "        f1w_t = f1_score(y_val, y_pred_t, average=\"weighted\", zero_division=0)\n",
        "        if f1w_t > best_f1:\n",
        "            best_f1 = f1w_t\n",
        "            best_t = t\n",
        "    return best_t, best_f1\n",
        "\n",
        "def eval_threshold(model, t):\n",
        "    probs = model.predict(test_loader, verbose=0)\n",
        "    y_true = test_loader.classes\n",
        "\n",
        "    ex_idx = train_loader.class_indices[\"Existent\"]\n",
        "    p_ex = probs[:, ex_idx]\n",
        "    y_pred = np.where(p_ex >= t, ex_idx, 1 - ex_idx)\n",
        "\n",
        "    return (accuracy_score(y_true, y_pred),\n",
        "            f1_score(y_true, y_pred, average=\"weighted\", zero_division=0))\n"
      ],
      "metadata": {
        "id": "_Grva0h4u_yp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import (\n",
        "    EfficientNetV2S,\n",
        "    ConvNeXtTiny,\n",
        "    DenseNet201,\n",
        "    ResNet101V2,\n",
        "    InceptionResNetV2\n",
        ")\n",
        "\n",
        "def make_model(backbone_name):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "\n",
        "    if backbone_name == \"EfficientNetV2S\":\n",
        "        base = EfficientNetV2S(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "        ft_last = 80\n",
        "    elif backbone_name == \"ConvNeXtTiny\":\n",
        "        base = ConvNeXtTiny(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "        ft_last = 60\n",
        "    elif backbone_name == \"DenseNet201\":\n",
        "        base = DenseNet201(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "        ft_last = 80\n",
        "    elif backbone_name == \"ResNet101V2\":\n",
        "        base = ResNet101V2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "        ft_last = 60\n",
        "    elif backbone_name == \"InceptionResNetV2\":\n",
        "        base = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
        "        ft_last = 60\n",
        "    else:\n",
        "        raise ValueError(\"Unknown backbone\")\n",
        "\n",
        "    # stage 1 freeze\n",
        "    base.trainable = False\n",
        "    outputs = build_head(base.output, 2)\n",
        "    model = models.Model(inputs, outputs, name=f\"Erythema_{backbone_name}\")\n",
        "\n",
        "    # stage 2 unfreeze last N layers\n",
        "    fine_tune_at = max(0, len(base.layers) - ft_last)\n",
        "    return model, base, fine_tune_at\n"
      ],
      "metadata": {
        "id": "eKNxcTyHvDNQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONES = [\"EfficientNetV2S\", \"ConvNeXtTiny\", \"DenseNet201\", \"ResNet101V2\", \"InceptionResNetV2\"]\n",
        "results = []\n",
        "\n",
        "for name in BACKBONES:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ðŸš€ Training:\", name)\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    model, base, fine_tune_at = make_model(name)\n",
        "\n",
        "    # Stage 1\n",
        "    print(\"ðŸ§© Stage 1: head warmup\")\n",
        "    fit_model(model, epochs=8, lr=1e-4)\n",
        "\n",
        "    # Stage 2\n",
        "    print(\"ðŸ”§ Stage 2: fine-tune\")\n",
        "    base.trainable = True\n",
        "    for layer in base.layers[:fine_tune_at]:\n",
        "        layer.trainable = False\n",
        "    fit_model(model, epochs=15, lr=1e-5)\n",
        "\n",
        "    acc_arg, f1_arg = eval_argmax(model)\n",
        "    best_t, best_val_f1 = best_threshold_on_val(model)\n",
        "    acc_thr, f1_thr = eval_threshold(model, best_t)\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Argmax_ACC\": acc_arg,\n",
        "        \"Argmax_F1W\": f1_arg,\n",
        "        \"Best_t(VAL)\": best_t,\n",
        "        \"Test_ACC@t\": acc_thr,\n",
        "        \"Test_F1W@t\": f1_thr\n",
        "    })\n",
        "\n",
        "    print(f\"âœ… {name} | Argmax ACC={acc_arg:.4f} F1W={f1_arg:.4f}\")\n",
        "    print(f\"âœ… {name} | Best t={best_t:.2f} -> TEST ACC={acc_thr:.4f} F1W={f1_thr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBz73lMYvGG1",
        "outputId": "04598f76-33fe-464e-959c-8f539c559872"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "ðŸš€ Training: EfficientNetV2S\n",
            "======================================================================\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n",
            "\u001b[1m82420632/82420632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "ðŸ§© Stage 1: head warmup\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3s/step - accuracy: 0.4237 - loss: 1.1953 - val_accuracy: 0.6212 - val_loss: 0.6816 - learning_rate: 1.0000e-04\n",
            "Epoch 2/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.5259 - loss: 0.9782 - val_accuracy: 0.5152 - val_loss: 0.6922 - learning_rate: 1.0000e-04\n",
            "Epoch 3/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 390ms/step - accuracy: 0.5193 - loss: 0.8467 - val_accuracy: 0.6212 - val_loss: 0.6919 - learning_rate: 1.0000e-04\n",
            "Epoch 4/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 385ms/step - accuracy: 0.5050 - loss: 1.0475 - val_accuracy: 0.5606 - val_loss: 0.6934 - learning_rate: 1.0000e-04\n",
            "Epoch 5/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 386ms/step - accuracy: 0.5324 - loss: 0.8142 - val_accuracy: 0.5606 - val_loss: 0.6954 - learning_rate: 5.0000e-05\n",
            "Epoch 6/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 386ms/step - accuracy: 0.5049 - loss: 0.8889 - val_accuracy: 0.5455 - val_loss: 0.6921 - learning_rate: 5.0000e-05\n",
            "Epoch 7/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 380ms/step - accuracy: 0.5540 - loss: 0.7589 - val_accuracy: 0.5606 - val_loss: 0.6939 - learning_rate: 5.0000e-05\n",
            "ðŸ”§ Stage 2: fine-tune\n",
            "Epoch 1/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.4872 - loss: 1.3386 - val_accuracy: 0.6667 - val_loss: 0.6732 - learning_rate: 1.0000e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 391ms/step - accuracy: 0.5417 - loss: 1.0351 - val_accuracy: 0.6212 - val_loss: 0.6790 - learning_rate: 1.0000e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 391ms/step - accuracy: 0.4907 - loss: 1.0419 - val_accuracy: 0.6061 - val_loss: 0.6823 - learning_rate: 1.0000e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 396ms/step - accuracy: 0.4960 - loss: 1.1303 - val_accuracy: 0.5758 - val_loss: 0.6845 - learning_rate: 1.0000e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 391ms/step - accuracy: 0.5086 - loss: 1.0262 - val_accuracy: 0.5606 - val_loss: 0.6848 - learning_rate: 5.0000e-06\n",
            "Epoch 6/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 394ms/step - accuracy: 0.5118 - loss: 1.0118 - val_accuracy: 0.6515 - val_loss: 0.6747 - learning_rate: 5.0000e-06\n",
            "Epoch 7/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 389ms/step - accuracy: 0.5301 - loss: 1.0434 - val_accuracy: 0.6515 - val_loss: 0.6769 - learning_rate: 5.0000e-06\n",
            "âœ… EfficientNetV2S | Argmax ACC=0.6107 F1W=0.6029\n",
            "âœ… EfficientNetV2S | Best t=0.50 -> TEST ACC=0.6107 F1W=0.6029\n",
            "\n",
            "======================================================================\n",
            "ðŸš€ Training: ConvNeXtTiny\n",
            "======================================================================\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_tiny_notop.h5\n",
            "\u001b[1m111650432/111650432\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n",
            "ðŸ§© Stage 1: head warmup\n",
            "Epoch 1/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.5935 - loss: 0.7839 - val_accuracy: 0.6667 - val_loss: 0.6599 - learning_rate: 1.0000e-04\n",
            "Epoch 2/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 382ms/step - accuracy: 0.5868 - loss: 0.7407 - val_accuracy: 0.6667 - val_loss: 0.6641 - learning_rate: 1.0000e-04\n",
            "Epoch 3/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.5472 - loss: 0.7884 - val_accuracy: 0.6515 - val_loss: 0.6616 - learning_rate: 1.0000e-04\n",
            "Epoch 4/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 378ms/step - accuracy: 0.5967 - loss: 0.7268 - val_accuracy: 0.6364 - val_loss: 0.6716 - learning_rate: 1.0000e-04\n",
            "Epoch 5/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 385ms/step - accuracy: 0.5722 - loss: 0.7832 - val_accuracy: 0.6212 - val_loss: 0.6792 - learning_rate: 5.0000e-05\n",
            "Epoch 6/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 398ms/step - accuracy: 0.5983 - loss: 0.6869 - val_accuracy: 0.5455 - val_loss: 0.6854 - learning_rate: 5.0000e-05\n",
            "Epoch 7/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.5225 - loss: 0.7617 - val_accuracy: 0.5606 - val_loss: 0.6816 - learning_rate: 5.0000e-05\n",
            "ðŸ”§ Stage 2: fine-tune\n",
            "Epoch 1/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 1s/step - accuracy: 0.5397 - loss: 0.8560 - val_accuracy: 0.6667 - val_loss: 0.6542 - learning_rate: 1.0000e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.5446 - loss: 0.7184 - val_accuracy: 0.6667 - val_loss: 0.6551 - learning_rate: 1.0000e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 383ms/step - accuracy: 0.5973 - loss: 0.7350 - val_accuracy: 0.6667 - val_loss: 0.6641 - learning_rate: 1.0000e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 383ms/step - accuracy: 0.5337 - loss: 0.7676 - val_accuracy: 0.6515 - val_loss: 0.6662 - learning_rate: 1.0000e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.5954 - loss: 0.6822 - val_accuracy: 0.6061 - val_loss: 0.6712 - learning_rate: 5.0000e-06\n",
            "Epoch 6/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 391ms/step - accuracy: 0.5438 - loss: 0.7558 - val_accuracy: 0.5758 - val_loss: 0.6776 - learning_rate: 5.0000e-06\n",
            "Epoch 7/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.5975 - loss: 0.6907 - val_accuracy: 0.5909 - val_loss: 0.6880 - learning_rate: 5.0000e-06\n",
            "âœ… ConvNeXtTiny | Argmax ACC=0.6870 F1W=0.5658\n",
            "âœ… ConvNeXtTiny | Best t=0.43 -> TEST ACC=0.6336 F1W=0.6418\n",
            "\n",
            "======================================================================\n",
            "ðŸš€ Training: DenseNet201\n",
            "======================================================================\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m74836368/74836368\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "ðŸ§© Stage 1: head warmup\n",
            "Epoch 1/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3s/step - accuracy: 0.5502 - loss: 0.9787 - val_accuracy: 0.5909 - val_loss: 0.7106 - learning_rate: 1.0000e-04\n",
            "Epoch 2/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 382ms/step - accuracy: 0.5859 - loss: 0.7533 - val_accuracy: 0.6212 - val_loss: 0.7168 - learning_rate: 1.0000e-04\n",
            "Epoch 3/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.6355 - loss: 0.7809 - val_accuracy: 0.6212 - val_loss: 0.7243 - learning_rate: 1.0000e-04\n",
            "Epoch 4/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.5903 - loss: 0.7524 - val_accuracy: 0.6212 - val_loss: 0.7425 - learning_rate: 1.0000e-04\n",
            "Epoch 5/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 382ms/step - accuracy: 0.6272 - loss: 0.7364 - val_accuracy: 0.6061 - val_loss: 0.7612 - learning_rate: 5.0000e-05\n",
            "Epoch 6/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.6341 - loss: 0.6715 - val_accuracy: 0.6061 - val_loss: 0.7704 - learning_rate: 5.0000e-05\n",
            "Epoch 7/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.6104 - loss: 0.7322 - val_accuracy: 0.5909 - val_loss: 0.7842 - learning_rate: 5.0000e-05\n",
            "ðŸ”§ Stage 2: fine-tune\n",
            "Epoch 1/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3s/step - accuracy: 0.5509 - loss: 0.7965 - val_accuracy: 0.6061 - val_loss: 0.6882 - learning_rate: 1.0000e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 394ms/step - accuracy: 0.6193 - loss: 0.7992 - val_accuracy: 0.6061 - val_loss: 0.6874 - learning_rate: 1.0000e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 382ms/step - accuracy: 0.6283 - loss: 0.7572 - val_accuracy: 0.5909 - val_loss: 0.6992 - learning_rate: 1.0000e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 382ms/step - accuracy: 0.5956 - loss: 0.8214 - val_accuracy: 0.6061 - val_loss: 0.7084 - learning_rate: 1.0000e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 387ms/step - accuracy: 0.6133 - loss: 0.7823 - val_accuracy: 0.6212 - val_loss: 0.7211 - learning_rate: 1.0000e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.5959 - loss: 0.7801 - val_accuracy: 0.6212 - val_loss: 0.7322 - learning_rate: 5.0000e-06\n",
            "Epoch 7/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.6271 - loss: 0.7393 - val_accuracy: 0.6212 - val_loss: 0.7404 - learning_rate: 5.0000e-06\n",
            "Epoch 8/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 379ms/step - accuracy: 0.6149 - loss: 0.7470 - val_accuracy: 0.6212 - val_loss: 0.7480 - learning_rate: 5.0000e-06\n",
            "âœ… DenseNet201 | Argmax ACC=0.5878 F1W=0.6039\n",
            "âœ… DenseNet201 | Best t=0.53 -> TEST ACC=0.5725 F1W=0.5853\n",
            "\n",
            "======================================================================\n",
            "ðŸš€ Training: ResNet101V2\n",
            "======================================================================\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m171317808/171317808\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 0us/step\n",
            "ðŸ§© Stage 1: head warmup\n",
            "Epoch 1/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.4571 - loss: 1.0470 - val_accuracy: 0.3788 - val_loss: 0.8539 - learning_rate: 1.0000e-04\n",
            "Epoch 2/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 391ms/step - accuracy: 0.5291 - loss: 0.9120 - val_accuracy: 0.4848 - val_loss: 0.7700 - learning_rate: 1.0000e-04\n",
            "Epoch 3/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 396ms/step - accuracy: 0.6443 - loss: 0.6796 - val_accuracy: 0.5758 - val_loss: 0.7214 - learning_rate: 1.0000e-04\n",
            "Epoch 4/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 389ms/step - accuracy: 0.6502 - loss: 0.7182 - val_accuracy: 0.5758 - val_loss: 0.7064 - learning_rate: 1.0000e-04\n",
            "Epoch 5/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 386ms/step - accuracy: 0.6592 - loss: 0.7076 - val_accuracy: 0.5909 - val_loss: 0.6933 - learning_rate: 1.0000e-04\n",
            "Epoch 6/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.6844 - loss: 0.6260 - val_accuracy: 0.6061 - val_loss: 0.7143 - learning_rate: 1.0000e-04\n",
            "Epoch 7/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 380ms/step - accuracy: 0.7178 - loss: 0.6124 - val_accuracy: 0.5909 - val_loss: 0.7166 - learning_rate: 1.0000e-04\n",
            "Epoch 8/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 380ms/step - accuracy: 0.7225 - loss: 0.6412 - val_accuracy: 0.6212 - val_loss: 0.7400 - learning_rate: 1.0000e-04\n",
            "ðŸ”§ Stage 2: fine-tune\n",
            "Epoch 1/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - accuracy: 0.6645 - loss: 0.7462 - val_accuracy: 0.6212 - val_loss: 0.6893 - learning_rate: 1.0000e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 383ms/step - accuracy: 0.6032 - loss: 0.7325 - val_accuracy: 0.6061 - val_loss: 0.7207 - learning_rate: 1.0000e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 377ms/step - accuracy: 0.6839 - loss: 0.6337 - val_accuracy: 0.6061 - val_loss: 0.7582 - learning_rate: 1.0000e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.6579 - loss: 0.5863 - val_accuracy: 0.5758 - val_loss: 0.8118 - learning_rate: 1.0000e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.7178 - loss: 0.5377 - val_accuracy: 0.5758 - val_loss: 0.8467 - learning_rate: 5.0000e-06\n",
            "Epoch 6/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 385ms/step - accuracy: 0.6458 - loss: 0.6943 - val_accuracy: 0.5606 - val_loss: 0.8657 - learning_rate: 5.0000e-06\n",
            "Epoch 7/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.7157 - loss: 0.5450 - val_accuracy: 0.5606 - val_loss: 0.8842 - learning_rate: 5.0000e-06\n",
            "âœ… ResNet101V2 | Argmax ACC=0.6260 F1W=0.6296\n",
            "âœ… ResNet101V2 | Best t=0.67 -> TEST ACC=0.6641 F1W=0.6305\n",
            "\n",
            "======================================================================\n",
            "ðŸš€ Training: InceptionResNetV2\n",
            "======================================================================\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m219055592/219055592\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n",
            "ðŸ§© Stage 1: head warmup\n",
            "Epoch 1/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.5474 - loss: 1.2079 - val_accuracy: 0.6515 - val_loss: 0.6538 - learning_rate: 1.0000e-04\n",
            "Epoch 2/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.5902 - loss: 0.8524 - val_accuracy: 0.7121 - val_loss: 0.6546 - learning_rate: 1.0000e-04\n",
            "Epoch 3/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 380ms/step - accuracy: 0.6476 - loss: 0.9189 - val_accuracy: 0.5606 - val_loss: 0.7311 - learning_rate: 1.0000e-04\n",
            "Epoch 4/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 382ms/step - accuracy: 0.6097 - loss: 0.7611 - val_accuracy: 0.5909 - val_loss: 0.7264 - learning_rate: 1.0000e-04\n",
            "Epoch 5/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 380ms/step - accuracy: 0.6327 - loss: 0.7714 - val_accuracy: 0.5909 - val_loss: 0.7324 - learning_rate: 5.0000e-05\n",
            "Epoch 6/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 397ms/step - accuracy: 0.6676 - loss: 0.8019 - val_accuracy: 0.5758 - val_loss: 0.7487 - learning_rate: 5.0000e-05\n",
            "Epoch 7/8\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 384ms/step - accuracy: 0.6764 - loss: 0.7519 - val_accuracy: 0.6364 - val_loss: 0.7361 - learning_rate: 5.0000e-05\n",
            "ðŸ”§ Stage 2: fine-tune\n",
            "Epoch 1/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.5603 - loss: 1.2941 - val_accuracy: 0.6818 - val_loss: 0.6426 - learning_rate: 1.0000e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 392ms/step - accuracy: 0.5861 - loss: 0.9420 - val_accuracy: 0.6970 - val_loss: 0.6391 - learning_rate: 1.0000e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 393ms/step - accuracy: 0.5947 - loss: 1.0287 - val_accuracy: 0.7273 - val_loss: 0.6362 - learning_rate: 1.0000e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 391ms/step - accuracy: 0.6205 - loss: 0.8726 - val_accuracy: 0.6970 - val_loss: 0.6330 - learning_rate: 1.0000e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.6151 - loss: 0.8743 - val_accuracy: 0.6667 - val_loss: 0.6422 - learning_rate: 1.0000e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 383ms/step - accuracy: 0.6439 - loss: 0.7244 - val_accuracy: 0.6364 - val_loss: 0.6524 - learning_rate: 1.0000e-05\n",
            "Epoch 7/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.6449 - loss: 0.7340 - val_accuracy: 0.5606 - val_loss: 0.6685 - learning_rate: 1.0000e-05\n",
            "Epoch 8/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 389ms/step - accuracy: 0.6483 - loss: 0.7519 - val_accuracy: 0.5455 - val_loss: 0.6794 - learning_rate: 5.0000e-06\n",
            "Epoch 9/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 381ms/step - accuracy: 0.6126 - loss: 0.7976 - val_accuracy: 0.5758 - val_loss: 0.6933 - learning_rate: 5.0000e-06\n",
            "Epoch 10/15\n",
            "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 382ms/step - accuracy: 0.6148 - loss: 0.8065 - val_accuracy: 0.6061 - val_loss: 0.6974 - learning_rate: 5.0000e-06\n",
            "âœ… InceptionResNetV2 | Argmax ACC=0.5649 F1W=0.5521\n",
            "âœ… InceptionResNetV2 | Best t=0.53 -> TEST ACC=0.5725 F1W=0.5480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results).sort_values(\"Test_F1W@t\", ascending=False)\n",
        "results_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "af-W9UWmvHxS",
        "outputId": "073bcca3-7549-4b51-c05b-95204ad136fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Model  Argmax_ACC  Argmax_F1W  Best_t(VAL)  Test_ACC@t  \\\n",
              "1       ConvNeXtTiny    0.687023    0.565784         0.43    0.633588   \n",
              "3        ResNet101V2    0.625954    0.629580         0.67    0.664122   \n",
              "0    EfficientNetV2S    0.610687    0.602915         0.50    0.610687   \n",
              "2        DenseNet201    0.587786    0.603901         0.53    0.572519   \n",
              "4  InceptionResNetV2    0.564885    0.552082         0.53    0.572519   \n",
              "\n",
              "   Test_F1W@t  \n",
              "1    0.641820  \n",
              "3    0.630480  \n",
              "0    0.602915  \n",
              "2    0.585311  \n",
              "4    0.548021  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c928f80-3bdc-4be5-97bf-13d8614daa22\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Argmax_ACC</th>\n",
              "      <th>Argmax_F1W</th>\n",
              "      <th>Best_t(VAL)</th>\n",
              "      <th>Test_ACC@t</th>\n",
              "      <th>Test_F1W@t</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ConvNeXtTiny</td>\n",
              "      <td>0.687023</td>\n",
              "      <td>0.565784</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.633588</td>\n",
              "      <td>0.641820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ResNet101V2</td>\n",
              "      <td>0.625954</td>\n",
              "      <td>0.629580</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.664122</td>\n",
              "      <td>0.630480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EfficientNetV2S</td>\n",
              "      <td>0.610687</td>\n",
              "      <td>0.602915</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.610687</td>\n",
              "      <td>0.602915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DenseNet201</td>\n",
              "      <td>0.587786</td>\n",
              "      <td>0.603901</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.572519</td>\n",
              "      <td>0.585311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>InceptionResNetV2</td>\n",
              "      <td>0.564885</td>\n",
              "      <td>0.552082</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.572519</td>\n",
              "      <td>0.548021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c928f80-3bdc-4be5-97bf-13d8614daa22')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c928f80-3bdc-4be5-97bf-13d8614daa22 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c928f80-3bdc-4be5-97bf-13d8614daa22');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_e13423a1-8896-48e0-9803-555b18b9407b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e13423a1-8896-48e0-9803-555b18b9407b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ResNet101V2\",\n          \"InceptionResNetV2\",\n          \"EfficientNetV2S\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Argmax_ACC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04630763629955146,\n        \"min\": 0.5648854961832062,\n        \"max\": 0.6870229007633588,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6259541984732825,\n          0.5648854961832062,\n          0.6106870229007634\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Argmax_F1W\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.031413321850068586,\n        \"min\": 0.5520815178872274,\n        \"max\": 0.6295796003323285,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6295796003323285,\n          0.5520815178872274,\n          0.6029146426092992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best_t(VAL)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08729261137118081,\n        \"min\": 0.43000000000000005,\n        \"max\": 0.6700000000000002,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6700000000000002,\n          0.5300000000000001,\n          0.43000000000000005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_ACC@t\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03966528566951629,\n        \"min\": 0.5725190839694656,\n        \"max\": 0.6641221374045801,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6641221374045801,\n          0.5725190839694656,\n          0.6335877862595419\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_F1W@t\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03738106269286389,\n        \"min\": 0.5480212388725066,\n        \"max\": 0.6418196176027186,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6304801772962325,\n          0.5480212388725066,\n          0.6029146426092992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(\"erythema_5models_results.csv\", index=False)\n",
        "print(\"âœ… Saved results to erythema_5models_results.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm0iM_MQ4Q2b",
        "outputId": "8ee99cba-1ced-442e-8dd3-50d8059d4594"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved results to erythema_5models_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TgoyQCYy8tUT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}